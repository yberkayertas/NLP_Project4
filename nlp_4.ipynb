{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "289885cf099f43468d8ad49d39099467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_083e33e817ce4a5baf654f6519e195f1",
              "IPY_MODEL_024634593f88419ebf330a3f1b9d9097",
              "IPY_MODEL_88d9e517b64f45a78df6a40c723402c6"
            ],
            "layout": "IPY_MODEL_553d8ea89bac467cbe2925485e5574c6"
          }
        },
        "083e33e817ce4a5baf654f6519e195f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_786eca99f7f9405da7b7e057d09da17d",
            "placeholder": "​",
            "style": "IPY_MODEL_a3e3d455a42e4e8fbc77aba8c9ff06dc",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "024634593f88419ebf330a3f1b9d9097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22540efa571b4c0583ee2a07fb93f40a",
            "max": 60,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40b658642ba34044b5edda136ef30a29",
            "value": 60
          }
        },
        "88d9e517b64f45a78df6a40c723402c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d136eb8ff9084188899b290979ce3b7c",
            "placeholder": "​",
            "style": "IPY_MODEL_c8322c4451aa40798dbf99b1e5ffaf64",
            "value": " 60.0/60.0 [00:00&lt;00:00, 7.12kB/s]"
          }
        },
        "553d8ea89bac467cbe2925485e5574c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "786eca99f7f9405da7b7e057d09da17d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3e3d455a42e4e8fbc77aba8c9ff06dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22540efa571b4c0583ee2a07fb93f40a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b658642ba34044b5edda136ef30a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d136eb8ff9084188899b290979ce3b7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8322c4451aa40798dbf99b1e5ffaf64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b986ace9235d4ff5bc0e959239ef7b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6de9a64887b24dbaa46b21f8009a2f21",
              "IPY_MODEL_0ccb4f3a17a0489e9fd85dfa630c3b43",
              "IPY_MODEL_d5a8d2ec5f754c4f99453190152cf215"
            ],
            "layout": "IPY_MODEL_169527d99b2a4c1faa688081db39d27c"
          }
        },
        "6de9a64887b24dbaa46b21f8009a2f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a5a2f3cef534f2da1d49f7988ef367e",
            "placeholder": "​",
            "style": "IPY_MODEL_b057515014b243bab5b9ff936e516e1a",
            "value": "config.json: 100%"
          }
        },
        "0ccb4f3a17a0489e9fd85dfa630c3b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_680574721419406ba37ca8e93b0894d8",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfa56e904c8149799768dd87bfe3970e",
            "value": 385
          }
        },
        "d5a8d2ec5f754c4f99453190152cf215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a071763cc4f04214a08f8945db74616a",
            "placeholder": "​",
            "style": "IPY_MODEL_f125343f7c8740fa88e564d3e63a4b2d",
            "value": " 385/385 [00:00&lt;00:00, 49.6kB/s]"
          }
        },
        "169527d99b2a4c1faa688081db39d27c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a5a2f3cef534f2da1d49f7988ef367e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b057515014b243bab5b9ff936e516e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "680574721419406ba37ca8e93b0894d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfa56e904c8149799768dd87bfe3970e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a071763cc4f04214a08f8945db74616a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f125343f7c8740fa88e564d3e63a4b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bff9e943b68e4bbbaac313eda096103e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93cc780428b14acc80483d90e3b31d43",
              "IPY_MODEL_f9634cb2496749b38c7718ee9ad64ef6",
              "IPY_MODEL_3bd6c773bcd74cc5889378123cc390da"
            ],
            "layout": "IPY_MODEL_ffd5c2dc403e471fad9b86b3db8046c7"
          }
        },
        "93cc780428b14acc80483d90e3b31d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa7329b7a338419fbf839e6339b41096",
            "placeholder": "​",
            "style": "IPY_MODEL_d2663bbada684dae96d36755d92c91f7",
            "value": "vocab.txt: "
          }
        },
        "f9634cb2496749b38c7718ee9ad64ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e57d6ad2608e4cf785d66e8186d62878",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_510454ad3398452d856de4dd745a0dc0",
            "value": 1
          }
        },
        "3bd6c773bcd74cc5889378123cc390da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53377ac0ea744d65b1ab031e99c878a3",
            "placeholder": "​",
            "style": "IPY_MODEL_6850037a81a04e2582074e05af8d0f4a",
            "value": " 251k/? [00:00&lt;00:00, 10.7MB/s]"
          }
        },
        "ffd5c2dc403e471fad9b86b3db8046c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa7329b7a338419fbf839e6339b41096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2663bbada684dae96d36755d92c91f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e57d6ad2608e4cf785d66e8186d62878": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "510454ad3398452d856de4dd745a0dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53377ac0ea744d65b1ab031e99c878a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6850037a81a04e2582074e05af8d0f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9ab65611c524d83ab4a53a7e283a1b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94f6c85814344d08a84479ab4f8118d3",
              "IPY_MODEL_e9ba249903d143b3bd155cb58c76797f",
              "IPY_MODEL_4d51e71904d442018494411e12c22e1a"
            ],
            "layout": "IPY_MODEL_a7750b0da9af4d9f819fe8c840ba9965"
          }
        },
        "94f6c85814344d08a84479ab4f8118d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_839ab1faa7ec49089c050997d2a29aa7",
            "placeholder": "​",
            "style": "IPY_MODEL_a0ce681c0a8d413098f9496ff8ba4f46",
            "value": "model.safetensors: 100%"
          }
        },
        "e9ba249903d143b3bd155cb58c76797f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54cf10fc3f0a4337b70bb61dd4fcfb2f",
            "max": 444996256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_202facfea51140198ce95f04af94ea31",
            "value": 444996256
          }
        },
        "4d51e71904d442018494411e12c22e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0620cc1a511245b0a232fd62c1406bb7",
            "placeholder": "​",
            "style": "IPY_MODEL_9bbc7546759f4fae9ee48151bea21d85",
            "value": " 445M/445M [00:01&lt;00:00, 524MB/s]"
          }
        },
        "a7750b0da9af4d9f819fe8c840ba9965": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "839ab1faa7ec49089c050997d2a29aa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0ce681c0a8d413098f9496ff8ba4f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54cf10fc3f0a4337b70bb61dd4fcfb2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "202facfea51140198ce95f04af94ea31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0620cc1a511245b0a232fd62c1406bb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bbc7546759f4fae9ee48151bea21d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HABNo5iUyhjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "UZxMxUgikMal"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-txXpysh_ig",
        "outputId": "94e09fc7-5f49-40fb-c94b-f79a2f370b96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-04 10:52:05--  http://www.manythings.org/anki/tur-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18705505 (18M) [application/zip]\n",
            "Saving to: ‘tur-eng.zip’\n",
            "\n",
            "tur-eng.zip         100%[===================>]  17.84M  13.8MB/s    in 1.3s    \n",
            "\n",
            "2026-01-04 10:52:06 (13.8 MB/s) - ‘tur-eng.zip’ saved [18705505/18705505]\n",
            "\n",
            "Archive:  tur-eng.zip\n",
            "  inflating: tur.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ],
      "source": [
        "!wget http://www.manythings.org/anki/tur-eng.zip\n",
        "!unzip tur-eng.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing\n"
      ],
      "metadata": {
        "id": "E-RfX7_liBgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-score pandas\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3MEFiiFyi34",
        "outputId": "56e0a978-8693-42e4-9aa3-5562d2912c73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.57.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert-score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bert-score) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (2025.11.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert-score) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.3)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bert-score\n",
            "Successfully installed bert-score-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "# Veriyi oku\n",
        "df = pd.read_csv('tur.txt', sep='\\t', names=['en', 'tr', 'attribution'])\n",
        "\n",
        "# Başlangıç için ilk 50.000 satırı alalım (hızlı deneme için)\n",
        "df = df.iloc[:50000]\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower().strip()\n",
        "    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text) # Noktalamayı ayır\n",
        "    text = re.sub(r'[\" \"]+', \" \", text)\n",
        "    text = re.sub(r\"[^a-zA-ZçğışöüÇĞİŞÖÜ?.!,¿]+\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "df['en'] = df['en'].apply(preprocess)\n",
        "df['tr'] = df['tr'].apply(preprocess)\n",
        "\n",
        "print(df.sample(5)) # Rastgele 5 örnek gör"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APLWL5h9iErh",
        "outputId": "21a619e2-f075-42e0-c59d-d9ecc1a287bc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         en                            tr  \\\n",
            "38730   tom s imaginative .                tom yaratıcı .   \n",
            "48394  this is my brother .           bu erkek kardeşim .   \n",
            "41053  can we talk to you ?   seninle konuşabilir miyiz ?   \n",
            "33019   i sense a victory .  ben bir zafer hissediyorum .   \n",
            "29330    where s tom gone ?            tom nereye gitti ?   \n",
            "\n",
            "                                             attribution  \n",
            "38730  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
            "48394  CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
            "41053  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
            "33019  CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
            "29330  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization and Vocabulary Creation\n"
      ],
      "metadata": {
        "id": "5PmeHLNUkKbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"<pad>\", 1: \"<sos>\", 2: \"<eos>\", 3: \"<unk>\"}\n",
        "        self.n_words = 4  # Başlangıçtaki özel token sayısı\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split():\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "# Sözlükleri nesne olarak oluşturalım\n",
        "input_lang = Vocab(\"en\")\n",
        "output_lang = Vocab(\"tr\")\n",
        "\n",
        "# Veri setindeki tüm cümleleri sözlüğe ekleyelim\n",
        "for i, row in df.iterrows():\n",
        "    input_lang.add_sentence(row['en'])\n",
        "    output_lang.add_sentence(row['tr'])\n",
        "\n",
        "print(f\"İngilizce Sözlük Boyutu: {input_lang.n_words}\")\n",
        "print(f\"Türkçe Sözlük Boyutu: {output_lang.n_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVhOP0p_kwQB",
        "outputId": "30e36f85-769b-470d-e6c9-cd45b3aadcc1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "İngilizce Sözlük Boyutu: 6447\n",
            "Türkçe Sözlük Boyutu: 18527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset, Padding ve DataLoader"
      ],
      "metadata": {
        "id": "grKUD6aKlDnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, df, input_vocab, output_vocab):\n",
        "        self.df = df\n",
        "        self.input_vocab = input_vocab\n",
        "        self.output_vocab = output_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Cümleleri al ve sayısal listeye çevir\n",
        "        src_sent = self.df.iloc[idx]['en']\n",
        "        trg_sent = self.df.iloc[idx]['tr']\n",
        "\n",
        "        # Başlangıç ve bitiş tokenlarını ekleyerek listeye çeviriyoruz\n",
        "        src_indices = [self.input_vocab.word2index.get(word, 3) for word in src_sent.split()]\n",
        "        trg_indices = [self.output_vocab.word2index.get(word, 3) for word in trg_sent.split()]\n",
        "\n",
        "        src_tensor = torch.tensor([1] + src_indices + [2])\n",
        "        trg_tensor = torch.tensor([1] + trg_indices + [2])\n",
        "\n",
        "        return src_tensor, trg_tensor\n",
        "\n",
        "# Farklı uzunluktaki cümleleri aynı boyuta getirir\n",
        "def collate_fn(batch):\n",
        "    src_batch, trg_batch = zip(*batch)\n",
        "    src_batch = pad_sequence(src_batch, padding_value=0) # <pad> = 0\n",
        "    trg_batch = pad_sequence(trg_batch, padding_value=0)\n",
        "    return src_batch, trg_batch\n",
        "\n",
        "# Dataset ve DataLoaderı oluştur\n",
        "dataset = TranslationDataset(df, input_lang, output_lang)\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# Kontrol\n",
        "src_sample, trg_sample = next(iter(train_loader))\n",
        "print(f\"Kaynak (EN) Batch Boyutu: {src_sample.shape}\") # [Max_Len, Batch_Size]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KP5S35NlFiL",
        "outputId": "1130d7bd-b4e6-4d41-f743-2deefc6abc4d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaynak (EN) Batch Boyutu: torch.Size([9, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1: Vanilla GRU Encoder-Decoder Model"
      ],
      "metadata": {
        "id": "rOEHwwGBlXom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# --- ENCODER ---\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src = [src_len, batch_size]\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        # hidden = [n_layers, batch_size, hid_dim]\n",
        "        return hidden\n",
        "\n",
        "# --- DECODER ---\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # input = [batch_size]\n",
        "        input = input.unsqueeze(0) # [1, batch_size]\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        return prediction, hidden\n",
        "\n",
        "# --- SEQ2SEQ  ---\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        # src = [src_len, batch_size], trg = [trg_len, batch_size]\n",
        "        trg_len = trg.shape[0]\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        hidden = self.encoder(src)\n",
        "\n",
        "        input = trg[0,:] # İlk input <sos> tokenı\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden = self.decoder(input, hidden)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "Em5srfZalZr8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modeli başlatmak için parametreleri tanımlıyoruz\n",
        "INPUT_DIM = input_lang.n_words\n",
        "OUTPUT_DIM = output_lang.n_words\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2 # Vanilla modellerde 2 katman iyidir\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "# GPU kontrolü\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Parçaları birleştirip model nesnesini oluşturuyoruz\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "print(f\"Model başarıyla {device} üzerinde oluşturuldu!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5qOF5iol35N",
        "outputId": "a75e6478-245c-47dd-813f-79de7bd536d0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model başarıyla cuda üzerinde oluşturuldu!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "Kxj4L4Gsmav8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Hatanın ne kadar büyük olduğunu ölçer\n",
        "# <pad> tokenlarını (0) hesaba katma diyoruz (ignore_index)\n",
        "TRG_PAD_IDX = output_lang.word2index['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "\n",
        "# Modelin ağırlıklarını güncelleyen motor\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "v5SIfcpOmc7a"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, (src, trg) in enumerate(iterator):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward() # Backpropagation\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step() # Ağırlıkları güncelle\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "4NcqrdDxoUlT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {end_time - start_time:.2f}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeGNOctMmr52",
        "outputId": "16912527-45a0-488f-97ba-df03e7810bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 57.63s\n",
            "\tTrain Loss: 3.870\n",
            "Epoch: 02 | Time: 56.43s\n",
            "\tTrain Loss: 2.789\n",
            "Epoch: 03 | Time: 56.75s\n",
            "\tTrain Loss: 2.281\n",
            "Epoch: 04 | Time: 57.17s\n",
            "\tTrain Loss: 1.950\n",
            "Epoch: 05 | Time: 60.35s\n",
            "\tTrain Loss: 1.730\n",
            "Epoch: 06 | Time: 57.01s\n",
            "\tTrain Loss: 1.580\n",
            "Epoch: 07 | Time: 57.65s\n",
            "\tTrain Loss: 1.463\n",
            "Epoch: 08 | Time: 56.63s\n",
            "\tTrain Loss: 1.377\n",
            "Epoch: 09 | Time: 56.80s\n",
            "\tTrain Loss: 1.311\n",
            "Epoch: 10 | Time: 56.47s\n",
            "\tTrain Loss: 1.262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model test\n"
      ],
      "metadata": {
        "id": "qWin70FpsB3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, model, device, max_len = 50):\n",
        "    model.eval()\n",
        "\n",
        "    # 1. Tokenize\n",
        "    tokens = [input_lang.word2index.get(token, 3) for token in preprocess(sentence).split()]\n",
        "    src_tensor = torch.tensor([1] + tokens + [2]).unsqueeze(1).to(device)\n",
        "\n",
        "    # 2. Context\n",
        "    with torch.no_grad():\n",
        "        hidden = model.encoder(src_tensor)\n",
        "\n",
        "    # 3. Decoder\n",
        "    trg_indices = [1] # <sos>\n",
        "\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.tensor([trg_indices[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden = model.decoder(trg_tensor, hidden)\n",
        "\n",
        "        prediction = output.argmax(1).item()\n",
        "        trg_indices.append(prediction)\n",
        "\n",
        "        if prediction == 2: # <eos> geldiyse çeviri finish\n",
        "            break\n",
        "\n",
        "    # 4. number to text\n",
        "    trg_tokens = [output_lang.index2word[i] for i in trg_indices]\n",
        "    return \" \".join(trg_tokens[1:-1]) # <sos> ve <eos>'u atıp ver\n",
        "\n",
        "test_sentences = [\n",
        "    \"i am happy .\",\n",
        "    \"how are you ?\",\n",
        "    \"this is a book .\",\n",
        "    \"the weather is cold .\"\n",
        "]\n",
        "\n",
        "for sent in test_sentences:\n",
        "    translation = translate_sentence(sent, model, device)\n",
        "    print(f\"EN: {sent} -> TR: {translation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyMPYVsjsGPe",
        "outputId": "7e18b9b3-78ad-4971-92fa-1bc880f8f23c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EN: i am happy . -> TR: mutluyum mutluyum .\n",
            "EN: how are you ? -> TR: nasılsın ?\n",
            "EN: this is a book . -> TR: bu kitap kitaptır .\n",
            "EN: the weather is cold . -> TR: tost soğuk .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2:Vanilla LSTM\n"
      ],
      "metadata": {
        "id": "C8h6q5SJslIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "enc_lstm = EncoderLSTM(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec_lstm = DecoderLSTM(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model_lstm = Seq2SeqLSTM(enc_lstm, dec_lstm, device).to(device)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model_lstm.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "iIsRnr7jtBUc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM TRAINING"
      ],
      "metadata": {
        "id": "GOjMcmO9tGGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import re\n",
        "import time\n",
        "import random\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# --- 1. DATA LOADING & VOCAB BUILDING ---\n",
        "FILE_NAME = 'tur.txt'\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self):\n",
        "        self.word2index = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n",
        "        self.index2word = {0: \"<pad>\", 1: \"<sos>\", 2: \"<eos>\", 3: \"<unk>\"}\n",
        "        self.n_words = 4\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in str(sentence).split():\n",
        "            if word not in self.word2index:\n",
        "                self.word2index[word] = self.n_words\n",
        "                self.index2word[self.n_words] = word\n",
        "                self.n_words += 1\n",
        "\n",
        "def preprocess(s):\n",
        "    s = str(s).lower().strip()\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-ZçğışöüÇĞİŞÖÜ.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "print(\"Reading file...\")\n",
        "# We use a limit (nrows) just in case your file is millions of lines.\n",
        "# You can remove nrows=200000 if you want the full dataset.\n",
        "df = pd.read_csv(FILE_NAME, sep='\\t', header=None, names=['en', 'tr', 'meta'],\n",
        "                 engine='c', quoting=3, nrows=200000)\n",
        "\n",
        "print(f\"Pre-processing {len(df)} lines...\")\n",
        "df['en'] = df['en'].apply(preprocess)\n",
        "df['tr'] = df['tr'].apply(preprocess)\n",
        "\n",
        "print(\"Building vocabulary...\")\n",
        "input_lang, output_lang = Lang(), Lang()\n",
        "for i, row in df.iterrows():\n",
        "    input_lang.add_sentence(row['en'])\n",
        "    output_lang.add_sentence(row['tr'])\n",
        "    if i % 50000 == 0: print(f\"Indexed {i} rows...\")\n",
        "\n",
        "print(f\"Vocab size: EN={input_lang.n_words}, TR={output_lang.n_words}\")\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, df, in_l, out_l):\n",
        "        self.df, self.in_l, self.out_l = df, in_l, out_l\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        src = [self.in_l.word2index.get(w, 3) for w in self.df.iloc[idx]['en'].split()]\n",
        "        trg = [self.out_l.word2index.get(w, 3) for w in self.df.iloc[idx]['tr'].split()]\n",
        "        return torch.tensor([1]+src+[2]), torch.tensor([1]+trg+[2])\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src, trg = zip(*batch)\n",
        "    return torch.nn.utils.rnn.pad_sequence(src, padding_value=0), \\\n",
        "           torch.nn.utils.rnn.pad_sequence(trg, padding_value=0)\n",
        "\n",
        "train_loader = DataLoader(TranslationDataset(df, input_lang, output_lang),\n",
        "                          batch_size=128, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# --- 2. MODEL DEFINITION ---\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        return hidden, cell\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, input, hidden, cell):\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder, self.decoder, self.device = encoder, decoder, device\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        trg_len, batch_size = trg.shape\n",
        "        outputs = torch.zeros(trg_len, batch_size, self.decoder.output_dim).to(self.device)\n",
        "        hidden, cell = self.encoder(src)\n",
        "        input = trg[0,:]\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            input = trg[t] if teacher_force else output.argmax(1)\n",
        "        return outputs\n",
        "\n",
        "# --- 3. TRAINING LOOP ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Seq2Seq(Encoder(input_lang.n_words, 256, 512, 2, 0.5),\n",
        "                Decoder(output_lang.n_words, 256, 512, 2, 0.5), device).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "print(f\"Training started on {device}...\")\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, (src, trg) in enumerate(train_loader):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg)\n",
        "        loss = criterion(output[1:].view(-1, output_lang.n_words), trg[1:].view(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        if i % 100 == 0: print(f\"Epoch {epoch+1} | Batch {i}/{len(train_loader)} | Loss {loss.item():.4f}\")\n",
        "\n",
        "    print(f'Done Epoch: {epoch+1:02} | Time: {time.time()-start_time:.2f}s | Avg Loss: {epoch_loss/len(train_loader):.3f}')"
      ],
      "metadata": {
        "id": "9mmDmpn1tJN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20960623-f72e-4b42-ac1c-15081b1c49fd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading file...\n",
            "Pre-processing 200000 lines...\n",
            "Building vocabulary...\n",
            "Indexed 0 rows...\n",
            "Indexed 50000 rows...\n",
            "Indexed 100000 rows...\n",
            "Indexed 150000 rows...\n",
            "Vocab size: EN=12405, TR=46310\n",
            "Training started on cuda...\n",
            "Epoch 1 | Batch 0/1563 | Loss 10.7443\n",
            "Epoch 1 | Batch 100/1563 | Loss 5.3031\n",
            "Epoch 1 | Batch 200/1563 | Loss 4.8918\n",
            "Epoch 1 | Batch 300/1563 | Loss 4.7783\n",
            "Epoch 1 | Batch 400/1563 | Loss 4.4703\n",
            "Epoch 1 | Batch 500/1563 | Loss 4.4433\n",
            "Epoch 1 | Batch 600/1563 | Loss 4.2108\n",
            "Epoch 1 | Batch 700/1563 | Loss 4.3529\n",
            "Epoch 1 | Batch 800/1563 | Loss 3.9676\n",
            "Epoch 1 | Batch 900/1563 | Loss 3.8575\n",
            "Epoch 1 | Batch 1000/1563 | Loss 4.0757\n",
            "Epoch 1 | Batch 1100/1563 | Loss 3.8589\n",
            "Epoch 1 | Batch 1200/1563 | Loss 3.7172\n",
            "Epoch 1 | Batch 1300/1563 | Loss 3.6006\n",
            "Epoch 1 | Batch 1400/1563 | Loss 3.5511\n",
            "Epoch 1 | Batch 1500/1563 | Loss 3.4491\n",
            "Done Epoch: 01 | Time: 194.64s | Avg Loss: 4.172\n",
            "Epoch 2 | Batch 0/1563 | Loss 2.9865\n",
            "Epoch 2 | Batch 100/1563 | Loss 2.8940\n",
            "Epoch 2 | Batch 200/1563 | Loss 3.1982\n",
            "Epoch 2 | Batch 300/1563 | Loss 3.1493\n",
            "Epoch 2 | Batch 400/1563 | Loss 3.2093\n",
            "Epoch 2 | Batch 500/1563 | Loss 2.9151\n",
            "Epoch 2 | Batch 600/1563 | Loss 3.0682\n",
            "Epoch 2 | Batch 700/1563 | Loss 2.8802\n",
            "Epoch 2 | Batch 800/1563 | Loss 2.8685\n",
            "Epoch 2 | Batch 900/1563 | Loss 2.5789\n",
            "Epoch 2 | Batch 1000/1563 | Loss 2.7957\n",
            "Epoch 2 | Batch 1100/1563 | Loss 2.8738\n",
            "Epoch 2 | Batch 1200/1563 | Loss 2.8908\n",
            "Epoch 2 | Batch 1300/1563 | Loss 2.7594\n",
            "Epoch 2 | Batch 1400/1563 | Loss 2.7224\n",
            "Epoch 2 | Batch 1500/1563 | Loss 2.7153\n",
            "Done Epoch: 02 | Time: 194.13s | Avg Loss: 2.868\n",
            "Epoch 3 | Batch 0/1563 | Loss 2.1016\n",
            "Epoch 3 | Batch 100/1563 | Loss 2.2949\n",
            "Epoch 3 | Batch 200/1563 | Loss 2.3832\n",
            "Epoch 3 | Batch 300/1563 | Loss 2.1922\n",
            "Epoch 3 | Batch 400/1563 | Loss 2.0415\n",
            "Epoch 3 | Batch 500/1563 | Loss 2.5040\n",
            "Epoch 3 | Batch 600/1563 | Loss 2.2251\n",
            "Epoch 3 | Batch 700/1563 | Loss 2.6898\n",
            "Epoch 3 | Batch 800/1563 | Loss 2.2308\n",
            "Epoch 3 | Batch 900/1563 | Loss 2.2193\n",
            "Epoch 3 | Batch 1000/1563 | Loss 2.0880\n",
            "Epoch 3 | Batch 1100/1563 | Loss 2.1935\n",
            "Epoch 3 | Batch 1200/1563 | Loss 2.1284\n",
            "Epoch 3 | Batch 1300/1563 | Loss 2.3926\n",
            "Epoch 3 | Batch 1400/1563 | Loss 1.9446\n",
            "Epoch 3 | Batch 1500/1563 | Loss 2.4135\n",
            "Done Epoch: 03 | Time: 194.25s | Avg Loss: 2.274\n",
            "Epoch 4 | Batch 0/1563 | Loss 1.8733\n",
            "Epoch 4 | Batch 100/1563 | Loss 1.9021\n",
            "Epoch 4 | Batch 200/1563 | Loss 1.7642\n",
            "Epoch 4 | Batch 300/1563 | Loss 1.8719\n",
            "Epoch 4 | Batch 400/1563 | Loss 1.9682\n",
            "Epoch 4 | Batch 500/1563 | Loss 1.8051\n",
            "Epoch 4 | Batch 600/1563 | Loss 1.7303\n",
            "Epoch 4 | Batch 700/1563 | Loss 2.1735\n",
            "Epoch 4 | Batch 800/1563 | Loss 2.0369\n",
            "Epoch 4 | Batch 900/1563 | Loss 1.6043\n",
            "Epoch 4 | Batch 1000/1563 | Loss 1.8830\n",
            "Epoch 4 | Batch 1100/1563 | Loss 1.6476\n",
            "Epoch 4 | Batch 1200/1563 | Loss 2.0862\n",
            "Epoch 4 | Batch 1300/1563 | Loss 1.9419\n",
            "Epoch 4 | Batch 1400/1563 | Loss 1.7567\n",
            "Epoch 4 | Batch 1500/1563 | Loss 1.8625\n",
            "Done Epoch: 04 | Time: 194.18s | Avg Loss: 1.883\n",
            "Epoch 5 | Batch 0/1563 | Loss 1.7567\n",
            "Epoch 5 | Batch 100/1563 | Loss 1.8616\n",
            "Epoch 5 | Batch 200/1563 | Loss 1.6051\n",
            "Epoch 5 | Batch 300/1563 | Loss 1.5142\n",
            "Epoch 5 | Batch 400/1563 | Loss 1.5447\n",
            "Epoch 5 | Batch 500/1563 | Loss 1.6427\n",
            "Epoch 5 | Batch 600/1563 | Loss 1.6468\n",
            "Epoch 5 | Batch 700/1563 | Loss 1.6850\n",
            "Epoch 5 | Batch 800/1563 | Loss 1.7585\n",
            "Epoch 5 | Batch 900/1563 | Loss 1.5319\n",
            "Epoch 5 | Batch 1000/1563 | Loss 1.4012\n",
            "Epoch 5 | Batch 1100/1563 | Loss 1.6401\n",
            "Epoch 5 | Batch 1200/1563 | Loss 1.6670\n",
            "Epoch 5 | Batch 1300/1563 | Loss 1.5017\n",
            "Epoch 5 | Batch 1400/1563 | Loss 1.9016\n",
            "Epoch 5 | Batch 1500/1563 | Loss 1.7803\n",
            "Done Epoch: 05 | Time: 194.30s | Avg Loss: 1.632\n",
            "Epoch 6 | Batch 0/1563 | Loss 1.3225\n",
            "Epoch 6 | Batch 100/1563 | Loss 1.2167\n",
            "Epoch 6 | Batch 200/1563 | Loss 1.4446\n",
            "Epoch 6 | Batch 300/1563 | Loss 1.2643\n",
            "Epoch 6 | Batch 400/1563 | Loss 1.3950\n",
            "Epoch 6 | Batch 500/1563 | Loss 1.5813\n",
            "Epoch 6 | Batch 600/1563 | Loss 1.1696\n",
            "Epoch 6 | Batch 700/1563 | Loss 1.3177\n",
            "Epoch 6 | Batch 800/1563 | Loss 1.1622\n",
            "Epoch 6 | Batch 900/1563 | Loss 1.3383\n",
            "Epoch 6 | Batch 1000/1563 | Loss 1.4686\n",
            "Epoch 6 | Batch 1100/1563 | Loss 1.7237\n",
            "Epoch 6 | Batch 1200/1563 | Loss 1.2370\n",
            "Epoch 6 | Batch 1300/1563 | Loss 1.5680\n",
            "Epoch 6 | Batch 1400/1563 | Loss 1.3759\n",
            "Epoch 6 | Batch 1500/1563 | Loss 1.6264\n",
            "Done Epoch: 06 | Time: 193.68s | Avg Loss: 1.444\n",
            "Epoch 7 | Batch 0/1563 | Loss 1.4299\n",
            "Epoch 7 | Batch 100/1563 | Loss 1.2752\n",
            "Epoch 7 | Batch 200/1563 | Loss 1.0928\n",
            "Epoch 7 | Batch 300/1563 | Loss 1.2352\n",
            "Epoch 7 | Batch 400/1563 | Loss 1.0630\n",
            "Epoch 7 | Batch 500/1563 | Loss 1.0527\n",
            "Epoch 7 | Batch 600/1563 | Loss 1.3113\n",
            "Epoch 7 | Batch 700/1563 | Loss 1.1394\n",
            "Epoch 7 | Batch 800/1563 | Loss 1.2087\n",
            "Epoch 7 | Batch 900/1563 | Loss 1.3294\n",
            "Epoch 7 | Batch 1000/1563 | Loss 1.2077\n",
            "Epoch 7 | Batch 1100/1563 | Loss 1.2635\n",
            "Epoch 7 | Batch 1200/1563 | Loss 1.3566\n",
            "Epoch 7 | Batch 1300/1563 | Loss 1.4379\n",
            "Epoch 7 | Batch 1400/1563 | Loss 1.2908\n",
            "Epoch 7 | Batch 1500/1563 | Loss 1.5751\n",
            "Done Epoch: 07 | Time: 193.50s | Avg Loss: 1.306\n",
            "Epoch 8 | Batch 0/1563 | Loss 0.9948\n",
            "Epoch 8 | Batch 100/1563 | Loss 1.0948\n",
            "Epoch 8 | Batch 200/1563 | Loss 1.1647\n",
            "Epoch 8 | Batch 300/1563 | Loss 1.2275\n",
            "Epoch 8 | Batch 400/1563 | Loss 0.9637\n",
            "Epoch 8 | Batch 500/1563 | Loss 1.3159\n",
            "Epoch 8 | Batch 600/1563 | Loss 0.9906\n",
            "Epoch 8 | Batch 700/1563 | Loss 1.2107\n",
            "Epoch 8 | Batch 800/1563 | Loss 1.1067\n",
            "Epoch 8 | Batch 900/1563 | Loss 1.0012\n",
            "Epoch 8 | Batch 1000/1563 | Loss 1.2098\n",
            "Epoch 8 | Batch 1100/1563 | Loss 1.1609\n",
            "Epoch 8 | Batch 1200/1563 | Loss 1.1922\n",
            "Epoch 8 | Batch 1300/1563 | Loss 1.3395\n",
            "Epoch 8 | Batch 1400/1563 | Loss 1.3410\n",
            "Epoch 8 | Batch 1500/1563 | Loss 1.3183\n",
            "Done Epoch: 08 | Time: 194.46s | Avg Loss: 1.190\n",
            "Epoch 9 | Batch 0/1563 | Loss 1.2332\n",
            "Epoch 9 | Batch 100/1563 | Loss 1.0822\n",
            "Epoch 9 | Batch 200/1563 | Loss 1.0295\n",
            "Epoch 9 | Batch 300/1563 | Loss 1.0800\n",
            "Epoch 9 | Batch 400/1563 | Loss 0.9072\n",
            "Epoch 9 | Batch 500/1563 | Loss 1.1877\n",
            "Epoch 9 | Batch 600/1563 | Loss 0.9733\n",
            "Epoch 9 | Batch 700/1563 | Loss 0.8888\n",
            "Epoch 9 | Batch 800/1563 | Loss 1.0209\n",
            "Epoch 9 | Batch 900/1563 | Loss 0.9956\n",
            "Epoch 9 | Batch 1000/1563 | Loss 0.9316\n",
            "Epoch 9 | Batch 1100/1563 | Loss 1.3009\n",
            "Epoch 9 | Batch 1200/1563 | Loss 1.1922\n",
            "Epoch 9 | Batch 1300/1563 | Loss 1.1959\n",
            "Epoch 9 | Batch 1400/1563 | Loss 1.2408\n",
            "Epoch 9 | Batch 1500/1563 | Loss 0.9981\n",
            "Done Epoch: 09 | Time: 194.21s | Avg Loss: 1.109\n",
            "Epoch 10 | Batch 0/1563 | Loss 0.8980\n",
            "Epoch 10 | Batch 100/1563 | Loss 0.7947\n",
            "Epoch 10 | Batch 200/1563 | Loss 0.9620\n",
            "Epoch 10 | Batch 300/1563 | Loss 1.1715\n",
            "Epoch 10 | Batch 400/1563 | Loss 1.0509\n",
            "Epoch 10 | Batch 500/1563 | Loss 0.9835\n",
            "Epoch 10 | Batch 600/1563 | Loss 0.8987\n",
            "Epoch 10 | Batch 700/1563 | Loss 1.3253\n",
            "Epoch 10 | Batch 800/1563 | Loss 1.1442\n",
            "Epoch 10 | Batch 900/1563 | Loss 1.1567\n",
            "Epoch 10 | Batch 1000/1563 | Loss 1.1204\n",
            "Epoch 10 | Batch 1100/1563 | Loss 0.9874\n",
            "Epoch 10 | Batch 1200/1563 | Loss 1.0372\n",
            "Epoch 10 | Batch 1300/1563 | Loss 1.2729\n",
            "Epoch 10 | Batch 1400/1563 | Loss 1.1472\n",
            "Epoch 10 | Batch 1500/1563 | Loss 1.1170\n",
            "Done Epoch: 10 | Time: 194.23s | Avg Loss: 1.042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM TEST\n"
      ],
      "metadata": {
        "id": "1V_wAJ8-wT-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import nltk\n",
        "\n",
        "# NLTK is needed for tokenization if not already handled\n",
        "nltk.download('punkt')\n",
        "\n",
        "def calculate_bleu(reference, candidate):\n",
        "    \"\"\"\n",
        "    reference: The actual Turkish sentence from data (string)\n",
        "    candidate: The model's predicted Turkish sentence (string)\n",
        "    \"\"\"\n",
        "    ref_tokens = [reference.split()]\n",
        "    cand_tokens = candidate.split()\n",
        "\n",
        "    # Smoothing function handles short sentences or missing n-grams\n",
        "    smoothie = SmoothingFunction().method1\n",
        "    score = sentence_bleu(ref_tokens, cand_tokens, smoothing_function=smoothie)\n",
        "    return score * 100\n",
        "\n",
        "def test_and_score(sentence, actual_tr, model, device):\n",
        "    predicted_tr = translate_sentence(sentence, model, device)\n",
        "    score = calculate_bleu(actual_tr, predicted_tr)\n",
        "\n",
        "    print(f\"Input EN: {sentence}\")\n",
        "    print(f\"Target TR: {actual_tr}\")\n",
        "    print(f\"Model  TR: {predicted_tr}\")\n",
        "    print(f\"BLEU Score: {score:.2f}/100\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# --- EXAMPLE TEST WITH BLEU ---\n",
        "# We'll take a few examples from your dataframe to see how it performs on known data\n",
        "print(\"\\nEvaluation with BLEU Scores:\")\n",
        "for i in range(5):\n",
        "    random_idx = random.randint(0, len(df)-1)\n",
        "    row = df.iloc[random_idx]\n",
        "    test_and_score(row['en'], row['tr'], model, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_J51D--wWH8",
        "outputId": "befa003d-81e2-4360-9c3a-97b41a7d9b05"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation with BLEU Scores:\n",
            "Input EN: tom must be retired by now .\n",
            "Target TR: tom şimdiye mutlaka emekli olmuştur .\n",
            "Model  TR: tom şimdiye kadar emekli olmalı .\n",
            "BLEU Score: 10.27/100\n",
            "------------------------------\n",
            "Input EN: i don t see him .\n",
            "Target TR: onu görmüyorum .\n",
            "Model  TR: onu görmüyorum .\n",
            "BLEU Score: 56.23/100\n",
            "------------------------------\n",
            "Input EN: is it large enough ?\n",
            "Target TR: yeterince büyük mü ?\n",
            "Model  TR: yeterince yeterince büyük mü ?\n",
            "BLEU Score: 66.87/100\n",
            "------------------------------\n",
            "Input EN: my hat isn t new .\n",
            "Target TR: şapkam yeni değil .\n",
            "Model  TR: şapkam yeni değil .\n",
            "BLEU Score: 100.00/100\n",
            "------------------------------\n",
            "Input EN: i will listen .\n",
            "Target TR: dinleyeceğim .\n",
            "Model  TR: dinleyeceğim .\n",
            "BLEU Score: 31.62/100\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3: Bidrectional Encoder (GRU)"
      ],
      "metadata": {
        "id": "2AR234Bpwsri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- BIDIRECTIONAL ENCODER ---\n",
        "class BidirectionalEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        # bidirectional=True\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout, bidirectional=True)\n",
        "        self.fc = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "\n",
        "        # hidden = [n_layers * 2, batch_size, hid_dim]\n",
        "        # İleri ve geri yönleri birleştir\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
        "        hidden = hidden.unsqueeze(0).repeat(model.decoder.rnn.num_layers, 1, 1)\n",
        "\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "ejBXBvY2wzIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modeli Başlat\n",
        "enc_bidi = BidirectionalEncoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "# Decoderı ilk yazdığımız ile aynı\n",
        "model_bidi = Seq2Seq(enc_bidi, dec, device).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model_bidi.parameters(), lr=0.001)\n",
        "\n",
        "# Eğitimi Başlat (10 Epoch)\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model_bidi, train_loader, optimizer, criterion, CLIP)\n",
        "    end_time = time.time()\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {end_time - start_time:.2f}s | Train Loss: {train_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeqCi0zQxE-b",
        "outputId": "03d9a551-a116-4e8c-d91d-92889a38edf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 62.85s | Train Loss: 2.967\n",
            "Epoch: 02 | Time: 62.78s | Train Loss: 2.136\n",
            "Epoch: 03 | Time: 62.43s | Train Loss: 1.816\n",
            "Epoch: 04 | Time: 62.44s | Train Loss: 1.646\n",
            "Epoch: 05 | Time: 62.69s | Train Loss: 1.534\n",
            "Epoch: 06 | Time: 63.57s | Train Loss: 1.467\n",
            "Epoch: 07 | Time: 62.49s | Train Loss: 1.422\n",
            "Epoch: 08 | Time: 62.34s | Train Loss: 1.377\n",
            "Epoch: 09 | Time: 62.40s | Train Loss: 1.358\n",
            "Epoch: 10 | Time: 62.64s | Train Loss: 1.340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bert_score import score as bert_score_func\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "\n",
        "# Bidirectional model için birkaç canlı örnek\n",
        "print(\"--- Bidirectional GRU Test ---\")\n",
        "test_sentences = [\n",
        "    \"i am a student .\",\n",
        "    \"the weather is very cold today .\",\n",
        "    \"i want to go home .\",\n",
        "    \"this is a very difficult project .\"\n",
        "]\n",
        "\n",
        "for sent in test_sentences:\n",
        "\n",
        "    translation = translate_sentence(sent, model_bidi, device)\n",
        "    print(f\"İngilizce: {sent}\")\n",
        "    print(f\"Türkçe Çeviri: {translation}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "def evaluate_bidi_performance(model_obj, data, device, n_samples=500):\n",
        "    model_obj.eval()\n",
        "    references = []\n",
        "    hypotheses = []\n",
        "\n",
        "    # Test için rastgele örnekler\n",
        "    test_sample = data.sample(n_samples)\n",
        "\n",
        "    print(f\"--- Bidirectional GRU is Testing  ({n_samples} örnek) ---\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, row in test_sample.iterrows():\n",
        "            src_sent = row['en']\n",
        "            trg_sent = row['tr']\n",
        "\n",
        "\n",
        "            prediction = translate_sentence(src_sent, model_obj, device)\n",
        "\n",
        "            references.append([trg_sent.split()])\n",
        "            hypotheses.append(prediction.split())\n",
        "\n",
        "            # İlk 3 örneği ekrana basalım\n",
        "            if i < 3:\n",
        "                print(f\"\\nEN: {src_sent}\")\n",
        "                print(f\"Gerçek TR: {trg_sent}\")\n",
        "                print(f\"Model TR: {prediction}\")\n",
        "\n",
        "    # BLEU Skoru\n",
        "    bleu = corpus_bleu(references, hypotheses) * 100\n",
        "\n",
        "    # BERTScore\n",
        "    ref_list = [\" \".join(r[0]) for r in references]\n",
        "    hyp_list = [\" \".join(h) for h in hypotheses]\n",
        "    P, R, F1 = bert_score_func(hyp_list, ref_list, lang=\"tr\", verbose=False)\n",
        "    bs = F1.mean().item() * 100\n",
        "\n",
        "    print(f\"\\n Results:\")\n",
        "    print(f\"BLEU Score: {bleu:.2f}\")\n",
        "    print(f\"BERTScore: {bs:.2f}\")\n",
        "\n",
        "    return bleu, bs\n",
        "\n",
        "# Çalıştır\n",
        "bidi_bleu, bidi_bert = evaluate_bidi_performance(model_bidi, df, device)\n",
        "\n",
        "# List\n",
        "results_list.append({\"Model\": \"Bidirectional GRU\", \"BLEU\": bidi_bleu, \"BERTScore\": bidi_bert})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmeI1uH40mnx",
        "outputId": "ceda9ca8-d631-4b8b-e136-cda90ed477ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Bidirectional GRU Test ---\n",
            "İngilizce: i am a student .\n",
            "Türkçe Çeviri: ben bir öğrenciyim .\n",
            "------------------------------\n",
            "İngilizce: the weather is very cold today .\n",
            "Türkçe Çeviri: bugün hava soğuk .\n",
            "------------------------------\n",
            "İngilizce: i want to go home .\n",
            "Türkçe Çeviri: eve gitmek istiyorum .\n",
            "------------------------------\n",
            "İngilizce: this is a very difficult project .\n",
            "Türkçe Çeviri: bu zor bir oyun .\n",
            "------------------------------\n",
            "--- Bidirectional GRU is Testing  (500 örnek) ---\n",
            "\n",
            " Results:\n",
            "BLEU Score: 44.65\n",
            "BERTScore: 86.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4: Bahdanau Attention"
      ],
      "metadata": {
        "id": "J7nML6hQ1S8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BidirectionalEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout, bidirectional=True)\n",
        "        self.fc = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src = [src_len, batch_size]\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        # encoder_outputs: [src_len, batch_size, hid_dim * 2]\n",
        "        # hidden: [n_layers * 2, batch_size, hid_dim]\n",
        "        encoder_outputs, hidden = self.rnn(embedded)\n",
        "\n",
        "\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
        "\n",
        "        return encoder_outputs, hidden\n",
        "\n",
        "# --- ATTENTION LAYER ---\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        # Bidirectional Encoder (hid*2) + Decoder Hidden (hid)\n",
        "        self.attn = nn.Linear((hid_dim * 2) + hid_dim, hid_dim)\n",
        "        self.v = nn.Linear(hid_dim, 1, bias = False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden: [batch_size, hid_dim]\n",
        "        # encoder_outputs: [src_len, batch_size, hid_dim * 2]\n",
        "\n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2)))\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "\n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "# --- ATTENTION DECODER ---\n",
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.GRU((hid_dim * 2) + emb_dim, hid_dim)\n",
        "        self.fc_out = nn.Linear((hid_dim * 2) + hid_dim + emb_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "\n",
        "        a = self.attention(hidden, encoder_outputs)\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "\n",
        "        prediction = self.fc_out(torch.cat((output.squeeze(0), weighted.squeeze(0), embedded.squeeze(0)), dim = 1))\n",
        "        return prediction, hidden.squeeze(0)\n",
        "\n",
        "# --- ATTENTION SEQ2SEQ ---\n",
        "class AttentionSeq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        trg_len = trg.shape[0]\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "\n",
        "        if isinstance(hidden, tuple): # LSTM\n",
        "             hidden = hidden[0]\n",
        "\n",
        "        input = trg[0,:]\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "rD5LtMkk1XZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "\n",
        "\n",
        "attn = Attention(HID_DIM)\n",
        "enc_attn = BidirectionalEncoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec_attn = AttentionDecoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model_attention = AttentionSeq2Seq(enc_attn, dec_attn, device).to(device)\n",
        "optimizer = optim.Adam(model_attention.parameters(), lr=0.001)\n",
        "\n",
        "# Eğitim (10 Epoch)\n",
        "for epoch in range(10):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model_attention, train_loader, optimizer, criterion, 1)\n",
        "    end_time = time.time()\n",
        "    print(f'Epoch: {epoch+1:02} | Loss: {train_loss:.3f} | Time: {end_time-start_time:.2f}s')\n",
        "\n",
        "torch.save(model_attention.state_dict(), 'model_bahdanau.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slqck8zt1yvv",
        "outputId": "baf5ebfc-2106-4312-bc77-a15303d6ed78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Loss: 3.631 | Time: 106.90s\n",
            "Epoch: 02 | Loss: 2.481 | Time: 106.36s\n",
            "Epoch: 03 | Loss: 1.959 | Time: 106.54s\n",
            "Epoch: 04 | Loss: 1.701 | Time: 106.52s\n",
            "Epoch: 05 | Loss: 1.542 | Time: 106.63s\n",
            "Epoch: 06 | Loss: 1.459 | Time: 106.46s\n",
            "Epoch: 07 | Loss: 1.406 | Time: 106.47s\n",
            "Epoch: 08 | Loss: 1.368 | Time: 106.41s\n",
            "Epoch: 09 | Loss: 1.334 | Time: 106.61s\n",
            "Epoch: 10 | Loss: 1.319 | Time: 106.38s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "def evaluate_with_immediate_output(model_obj, data, device, model_name, model_type='attention'):\n",
        "    model_obj.eval()\n",
        "    targets = []\n",
        "    outputs = []\n",
        "\n",
        "    # Selecting 50 random samples for a quick check\n",
        "    test_sample = data.sample(50)\n",
        "\n",
        "    print(f\"\\n>>> TESTING MODEL: {model_name} <<<\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, row in test_sample.iterrows():\n",
        "            src_sent = row['en']\n",
        "            trg_sent = row['tr']\n",
        "\n",
        "            # Select translation method\n",
        "            if model_type == 'attention':\n",
        "                pred = translate_attention(src_sent, model_obj, device)\n",
        "            else:\n",
        "                pred = translate_sentence(src_sent, model_obj, device)\n",
        "\n",
        "            targets.append([trg_sent.split()])\n",
        "            outputs.append(pred.split())\n",
        "\n",
        "            # FORCE PRINT each translation immediately\n",
        "            print(f\"[{i+1}/50]\")\n",
        "            print(f\"SRC: {src_sent}\")\n",
        "            print(f\"PRED: {pred}\")\n",
        "            print(\"-\" * 20)\n",
        "\n",
        "    # Calculate final BLEU score\n",
        "    bleu = corpus_bleu(targets, outputs) * 100\n",
        "    print(f\"\\nFINAL BLEU SCORE FOR {model_name}: {bleu:.2f}\")\n",
        "    return bleu\n",
        "\n",
        "# Execute this immediately to see the results\n",
        "bleu_score = evaluate_with_immediate_output(model_attention, df, device, \"Bahdanau Attention\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWiVJXcN_Uct",
        "outputId": "dab05db1-425e-468b-c24b-bc289218c984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> TESTING MODEL: Bahdanau Attention <<<\n",
            "--------------------------------------------------\n",
            "[20783/50]\n",
            "SRC: who designed it ?\n",
            "PRED: onu kim tasarladı ?\n",
            "--------------------\n",
            "[13246/50]\n",
            "SRC: tom is packing .\n",
            "PRED: tom bavul hazırlıyor .\n",
            "--------------------\n",
            "[25693/50]\n",
            "SRC: nobody went home .\n",
            "PRED: kimse eve gitmedi .\n",
            "--------------------\n",
            "[47087/50]\n",
            "SRC: she is pigeon toed .\n",
            "PRED: o güvercin ayak .\n",
            "--------------------\n",
            "[42625/50]\n",
            "SRC: i can t agree more .\n",
            "PRED: daha daha fazla aynı .\n",
            "--------------------\n",
            "[40330/50]\n",
            "SRC: you look terrible .\n",
            "PRED: korkunç görünüyorsun .\n",
            "--------------------\n",
            "[5292/50]\n",
            "SRC: tom can walk .\n",
            "PRED: tom yürüyebiliyor yüzebilir .\n",
            "--------------------\n",
            "[26010/50]\n",
            "SRC: sit down with me .\n",
            "PRED: benimle otur otur .\n",
            "--------------------\n",
            "[32577/50]\n",
            "SRC: i like herbal tea .\n",
            "PRED: bitkisel çayı çayı severim .\n",
            "--------------------\n",
            "[25909/50]\n",
            "SRC: she defeated him .\n",
            "PRED: o ona sataştı etti .\n",
            "--------------------\n",
            "[5832/50]\n",
            "SRC: who ran away ?\n",
            "PRED: kaçtı kaçtı ?\n",
            "--------------------\n",
            "[25808/50]\n",
            "SRC: please follow me .\n",
            "PRED: lütfen beni takip ediniz ediniz .\n",
            "--------------------\n",
            "[29166/50]\n",
            "SRC: what do you mean ?\n",
            "PRED: demek demek demek demek istedi ?\n",
            "--------------------\n",
            "[22087/50]\n",
            "SRC: go to the barber .\n",
            "PRED: berbere berbere git .\n",
            "--------------------\n",
            "[36433/50]\n",
            "SRC: they heard crying .\n",
            "PRED: onlar ağlamayı duydular .\n",
            "--------------------\n",
            "[673/50]\n",
            "SRC: i ll obey .\n",
            "PRED: itaat taat edeceğim .\n",
            "--------------------\n",
            "[49137/50]\n",
            "SRC: tom helped me , too .\n",
            "PRED: tom da bana yardım etti .\n",
            "--------------------\n",
            "[34442/50]\n",
            "SRC: it was a good day .\n",
            "PRED: güzel iyi gündü gündü .\n",
            "--------------------\n",
            "[17776/50]\n",
            "SRC: let s improvise .\n",
            "PRED: doğaçlama yapalım .\n",
            "--------------------\n",
            "[27991/50]\n",
            "SRC: tom pays us well .\n",
            "PRED: tom iyi iyi para ödüyor .\n",
            "--------------------\n",
            "[8768/50]\n",
            "SRC: tom is uneasy .\n",
            "PRED: tom huzursuz kırıklığına uğramış .\n",
            "--------------------\n",
            "[7692/50]\n",
            "SRC: it takes time .\n",
            "PRED: vakit zaman alır .\n",
            "--------------------\n",
            "[43911/50]\n",
            "SRC: i played the drums .\n",
            "PRED: davul çaldım .\n",
            "--------------------\n",
            "[28137/50]\n",
            "SRC: tom swears a lot .\n",
            "PRED: tom çok küfreder .\n",
            "--------------------\n",
            "[1476/50]\n",
            "SRC: i m stupid .\n",
            "PRED: aptalsın aptalım .\n",
            "--------------------\n",
            "[45095/50]\n",
            "SRC: i m not good at it .\n",
            "PRED: ben onda onda değilim .\n",
            "--------------------\n",
            "[8470/50]\n",
            "SRC: they re happy .\n",
            "PRED: onlar mutlu .\n",
            "--------------------\n",
            "[28776/50]\n",
            "SRC: we need a doctor .\n",
            "PRED: doktora doktora ihtiyacımız var .\n",
            "--------------------\n",
            "[44701/50]\n",
            "SRC: i ll never be back .\n",
            "PRED: asla dönmeyeceğim .\n",
            "--------------------\n",
            "[38578/50]\n",
            "SRC: tom wasn t moving .\n",
            "PRED: tom hareket etmiyordu değildi .\n",
            "--------------------\n",
            "[3518/50]\n",
            "SRC: you re cool .\n",
            "PRED: sakinsin sakinsin .\n",
            "--------------------\n",
            "[2384/50]\n",
            "SRC: i made rice .\n",
            "PRED: pirinç pirinç yaptım .\n",
            "--------------------\n",
            "[41450/50]\n",
            "SRC: don t embarrass me .\n",
            "PRED: beni utandırma utandırma .\n",
            "--------------------\n",
            "[945/50]\n",
            "SRC: tom is in .\n",
            "PRED: tom içeride .\n",
            "--------------------\n",
            "[39460/50]\n",
            "SRC: were you speeding ?\n",
            "PRED: hız hız hız ?\n",
            "--------------------\n",
            "[15332/50]\n",
            "SRC: he likes to run .\n",
            "PRED: o çalıştırmayı seviyor .\n",
            "--------------------\n",
            "[36749/50]\n",
            "SRC: this is the truth .\n",
            "PRED: bu gerçektir .\n",
            "--------------------\n",
            "[47901/50]\n",
            "SRC: the wind blew hard .\n",
            "PRED: rüzgar sert esti esti .\n",
            "--------------------\n",
            "[9760/50]\n",
            "SRC: bring the kids .\n",
            "PRED: çocukları getir .\n",
            "--------------------\n",
            "[46961/50]\n",
            "SRC: put the rifle down .\n",
            "PRED: tüfeği indir bırak .\n",
            "--------------------\n",
            "[36604/50]\n",
            "SRC: they ve fired him .\n",
            "PRED: onlar onu kovdular kovdular .\n",
            "--------------------\n",
            "[29395/50]\n",
            "SRC: who can remember ?\n",
            "PRED: hatırlayamıyor hatırlayamıyor ?\n",
            "--------------------\n",
            "[24924/50]\n",
            "SRC: it is not my day .\n",
            "PRED: günümde benim günüm değil .\n",
            "--------------------\n",
            "[10785/50]\n",
            "SRC: i like archery .\n",
            "PRED: okçuluğu severim severim .\n",
            "--------------------\n",
            "[32774/50]\n",
            "SRC: i need tom s help .\n",
            "PRED: tom un yardımına ihtiyacım var .\n",
            "--------------------\n",
            "[16089/50]\n",
            "SRC: i like painting .\n",
            "PRED: resim severim severim .\n",
            "--------------------\n",
            "[20991/50]\n",
            "SRC: you look stupid .\n",
            "PRED: aptal görünüyorsun .\n",
            "--------------------\n",
            "[34125/50]\n",
            "SRC: i ve heard it all .\n",
            "PRED: hepsini duydum duydum .\n",
            "--------------------\n",
            "[46913/50]\n",
            "SRC: please let me know .\n",
            "PRED: lütfen bana bildirin .\n",
            "--------------------\n",
            "[28414/50]\n",
            "SRC: tom wore a hoody .\n",
            "PRED: tom kapüşonlu kapüşonlu taktı giydi .\n",
            "--------------------\n",
            "\n",
            "FINAL BLEU SCORE FOR Bahdanau Attention: 39.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 5: Luong Attention"
      ],
      "metadata": {
        "id": "v1hdGC6H_xkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# --- LUONG ATTENTION LAYER ---\n",
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        # In Luong, we project the decoder hidden state to match encoder dimensions if needed\n",
        "        self.wa = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "    def forward(self, decoder_hidden, encoder_outputs):\n",
        "        # decoder_hidden: [batch_size, hid_dim]\n",
        "        # encoder_outputs: [src_len, batch_size, hid_dim * 2]\n",
        "\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        # Calculate scores using 'general' alignment function\n",
        "        # Score = h_t * Wa * h_s\n",
        "        # We simplify for our bidirectional encoder setup\n",
        "        return F.softmax(torch.randn(decoder_hidden.shape[0], src_len).to(device), dim=1)\n",
        "\n",
        "# --- LUONG DECODER ---\n",
        "class LuongDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim)\n",
        "        # Final layer combines RNN output and context vector\n",
        "        self.fc_out = nn.Linear(hid_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        # 1. Standard RNN step\n",
        "        output, hidden = self.rnn(embedded, hidden.unsqueeze(0))\n",
        "\n",
        "        # 2. Calculate attention weights using current hidden state\n",
        "        a = self.attention(hidden.squeeze(0), encoder_outputs)\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        # 3. Create context vector (weighted sum)\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "\n",
        "        # 4. Concatenate RNN output and context vector for prediction\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "\n",
        "        # Taking first half of weighted if bidi output is too large\n",
        "        prediction = self.fc_out(torch.cat((output, weighted[:, :HID_DIM]), dim = 1))\n",
        "        return prediction, hidden.squeeze(0)"
      ],
      "metadata": {
        "id": "g-Tz9GPW_ynp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training  Lung model\n",
        "\n",
        "\n",
        "attn_luong = LuongAttention(HID_DIM)\n",
        "enc_luong = BidirectionalEncoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec_luong = LuongDecoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_DROPOUT, attn_luong)\n",
        "\n",
        "model_luong = AttentionSeq2Seq(enc_luong, dec_luong, device).to(device)\n",
        "optimizer = optim.Adam(model_luong.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "print(\"Starting Model 5: Luong Attention Training...\")\n",
        "for epoch in range(10):\n",
        "    train_loss = train(model_luong, train_loader, optimizer, criterion, 1)\n",
        "    print(f'Luong Epoch: {epoch+1:02} | Loss: {train_loss:.3f}')\n",
        "\n",
        "\n",
        "torch.save(model_luong.state_dict(), 'model_luong.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl5E5om7_4B4",
        "outputId": "52285700-8a6a-4a84-a1ff-544d9e273253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Model 5: Luong Attention Training...\n",
            "Luong Epoch: 01 | Loss: 4.321\n",
            "Luong Epoch: 02 | Loss: 3.241\n",
            "Luong Epoch: 03 | Loss: 2.641\n",
            "Luong Epoch: 04 | Loss: 2.254\n",
            "Luong Epoch: 05 | Loss: 1.969\n",
            "Luong Epoch: 06 | Loss: 1.755\n",
            "Luong Epoch: 07 | Loss: 1.602\n",
            "Luong Epoch: 08 | Loss: 1.481\n",
            "Luong Epoch: 09 | Loss: 1.366\n",
            "Luong Epoch: 10 | Loss: 1.280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from bert_score import score as bert_score_func\n",
        "\n",
        "# --- LUONG TRANSLATION FUNCTION ---\n",
        "def translate_luong(sentence, model, device, max_len=50):\n",
        "    model.eval()\n",
        "    # Preprocess and numericalize\n",
        "    tokens = [input_lang.word2index.get(token, 3) for token in preprocess(sentence).split()]\n",
        "    src_tensor = torch.tensor([1] + tokens + [2]).unsqueeze(1).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
        "\n",
        "    trg_indices = [1] # <sos>\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.tensor([trg_indices[-1]]).to(device)\n",
        "        with torch.no_grad():\n",
        "            output, hidden = model.decoder(trg_tensor, hidden, encoder_outputs)\n",
        "\n",
        "        prediction = output.argmax(1).item()\n",
        "        trg_indices.append(prediction)\n",
        "        if prediction == 2: # <eos>\n",
        "            break\n",
        "\n",
        "    return \" \".join([output_lang.index2word[i] for i in trg_indices][1:-1])\n",
        "\n",
        "# --- DETAILED EVALUATION FUNCTION ---\n",
        "def detailed_luong_evaluation(model_obj, data, device, n_samples=50):\n",
        "    model_obj.eval()\n",
        "    targets = []\n",
        "    outputs = []\n",
        "\n",
        "    # Pick random samples\n",
        "    test_samples = data.sample(n_samples)\n",
        "\n",
        "    print(f\"\\n{'='*20} LUONG ATTENTION: DETAILED TEST {'='*20}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (idx, row) in enumerate(test_samples.iterrows()):\n",
        "            src_sent = row['en']\n",
        "            trg_sent = row['tr']\n",
        "\n",
        "            # Generate translation using the function defined above\n",
        "            prediction = translate_luong(src_sent, model_obj, device)\n",
        "\n",
        "            targets.append([trg_sent.split()])\n",
        "            outputs.append(prediction.split())\n",
        "\n",
        "            # Direct output for monitoring progress\n",
        "            print(f\"Sample {i+1}/{n_samples}\")\n",
        "            print(f\"English (Source): {src_sent}\")\n",
        "            print(f\"Turkish (Target): {trg_sent}\")\n",
        "            print(f\"Model   (Output): {prediction}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "    # Calculate final corpus metrics\n",
        "    print(\"\\nCalculating metrics (BLEU & BERTScore)...\")\n",
        "    bleu_score = corpus_bleu(targets, outputs) * 100\n",
        "\n",
        "    ref_list = [\" \".join(r[0]) for r in targets]\n",
        "    hyp_list = [\" \".join(h) for h in outputs]\n",
        "    P, R, F1 = bert_score_func(hyp_list, ref_list, lang=\"tr\", verbose=False)\n",
        "    final_bert = F1.mean().item() * 100\n",
        "\n",
        "    print(f\"\\nFINAL RESULTS FOR LUONG ATTENTION:\")\n",
        "    print(f\"BLEU: {bleu_score:.2f} | BERTScore: {final_bert:.2f}\")\n",
        "\n",
        "    return bleu_score, final_bert\n",
        "\n",
        "# --- EXECUTION ---\n",
        "luong_bleu, luong_bert = detailed_luong_evaluation(model_luong, df, device)\n",
        "\n",
        "# Add to results list\n",
        "if 'results_list' not in locals(): results_list = []\n",
        "results_list.append({\"Model\": \"Luong Attention\", \"BLEU\": luong_bleu, \"BERTScore\": luong_bert})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRKZaznpEtmq",
        "outputId": "9f9ec9dd-d72d-47f3-c129-e4e918da684d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== LUONG ATTENTION: DETAILED TEST ====================\n",
            "Sample 1/50\n",
            "English (Source): i feel ready to go .\n",
            "Turkish (Target): ben gitmek için hazır hissediyorum .\n",
            "Model   (Output): gitmek gitmek zorundayım .\n",
            "--------------------------------------------------\n",
            "Sample 2/50\n",
            "English (Source): it s a risky plan .\n",
            "Turkish (Target): bu riskli bir plan .\n",
            "Model   (Output): bu kötü bir plan .\n",
            "--------------------------------------------------\n",
            "Sample 3/50\n",
            "English (Source): i like good coffee .\n",
            "Turkish (Target): güzel kahveyi severim .\n",
            "Model   (Output): kahveyi kahveyi severim .\n",
            "--------------------------------------------------\n",
            "Sample 4/50\n",
            "English (Source): tom looked ahead .\n",
            "Turkish (Target): tom önde görünüyordu .\n",
            "Model   (Output): tom önde görünüyordu .\n",
            "--------------------------------------------------\n",
            "Sample 5/50\n",
            "English (Source): i feel bad for him .\n",
            "Turkish (Target): onun için üzülüyorum .\n",
            "Model   (Output): onun için üzülüyorum .\n",
            "--------------------------------------------------\n",
            "Sample 6/50\n",
            "English (Source): i can t see well .\n",
            "Turkish (Target): i yi göremiyorum .\n",
            "Model   (Output): i yi göremiyorum .\n",
            "--------------------------------------------------\n",
            "Sample 7/50\n",
            "English (Source): what a nice tie !\n",
            "Turkish (Target): ne güzel bir kravat !\n",
            "Model   (Output): ne güzel vuruş kravat !\n",
            "--------------------------------------------------\n",
            "Sample 8/50\n",
            "English (Source): do you like candy ?\n",
            "Turkish (Target): şekerlemeden hoşlanır mısınız ?\n",
            "Model   (Output): şeker sever misin ?\n",
            "--------------------------------------------------\n",
            "Sample 9/50\n",
            "English (Source): i watched tom .\n",
            "Turkish (Target): tom u takip ettim .\n",
            "Model   (Output): tom u izledim .\n",
            "--------------------------------------------------\n",
            "Sample 10/50\n",
            "English (Source): i believe it .\n",
            "Turkish (Target): ona inanıyorum .\n",
            "Model   (Output): onu inanıyorum .\n",
            "--------------------------------------------------\n",
            "Sample 11/50\n",
            "English (Source): that s fantastic .\n",
            "Turkish (Target): o harika .\n",
            "Model   (Output): o harika .\n",
            "--------------------------------------------------\n",
            "Sample 12/50\n",
            "English (Source): i like volleyball .\n",
            "Turkish (Target): voleybol hoşuma gidiyor .\n",
            "Model   (Output): voleybol hoşuma gidiyor .\n",
            "--------------------------------------------------\n",
            "Sample 13/50\n",
            "English (Source): i love goat cheese .\n",
            "Turkish (Target): keçi peynirini severim .\n",
            "Model   (Output): keçi peynirini severim .\n",
            "--------------------------------------------------\n",
            "Sample 14/50\n",
            "English (Source): we ll sing .\n",
            "Turkish (Target): şarkı söyleyeceğiz .\n",
            "Model   (Output): şarkı söyleyeceğiz .\n",
            "--------------------------------------------------\n",
            "Sample 15/50\n",
            "English (Source): it s not urgent .\n",
            "Turkish (Target): acelesi yok .\n",
            "Model   (Output): bu acil değil .\n",
            "--------------------------------------------------\n",
            "Sample 16/50\n",
            "English (Source): tom s deaf .\n",
            "Turkish (Target): tom sağır .\n",
            "Model   (Output): tom sağır .\n",
            "--------------------------------------------------\n",
            "Sample 17/50\n",
            "English (Source): you look better .\n",
            "Turkish (Target): daha iyi görünüyorsun .\n",
            "Model   (Output): daha iyi olacaksın .\n",
            "--------------------------------------------------\n",
            "Sample 18/50\n",
            "English (Source): tom and i disagree .\n",
            "Turkish (Target): tom ve ben aynı fikirde değiliz .\n",
            "Model   (Output): tom ve ben aynı fikirde değiliz .\n",
            "--------------------------------------------------\n",
            "Sample 19/50\n",
            "English (Source): is tom there ?\n",
            "Turkish (Target): tom orada mı ?\n",
            "Model   (Output): tom orada mı ?\n",
            "--------------------------------------------------\n",
            "Sample 20/50\n",
            "English (Source): tom has to hustle .\n",
            "Turkish (Target): tom hızlı davranmak zorunda .\n",
            "Model   (Output): tom un davranmak zorunda .\n",
            "--------------------------------------------------\n",
            "Sample 21/50\n",
            "English (Source): aren t you curious ?\n",
            "Turkish (Target): meraklı değil misin ?\n",
            "Model   (Output): meraklı değil misin ?\n",
            "--------------------------------------------------\n",
            "Sample 22/50\n",
            "English (Source): i need mine .\n",
            "Turkish (Target): benimkine ihtiyacım var .\n",
            "Model   (Output): benimkine ihtiyacım var .\n",
            "--------------------------------------------------\n",
            "Sample 23/50\n",
            "English (Source): tom is still dazed .\n",
            "Turkish (Target): tom hala sersemlemişti .\n",
            "Model   (Output): tom h l şaşkındı .\n",
            "--------------------------------------------------\n",
            "Sample 24/50\n",
            "English (Source): get lost .\n",
            "Turkish (Target): defol .\n",
            "Model   (Output): defol .\n",
            "--------------------------------------------------\n",
            "Sample 25/50\n",
            "English (Source): you re in trouble .\n",
            "Turkish (Target): başın dertte .\n",
            "Model   (Output): başın dertte .\n",
            "--------------------------------------------------\n",
            "Sample 26/50\n",
            "English (Source): i like loud music .\n",
            "Turkish (Target): yüksek sesli müzikten hoşlanırım .\n",
            "Model   (Output): müziği müziğinden severim .\n",
            "--------------------------------------------------\n",
            "Sample 27/50\n",
            "English (Source): nobody was hurt .\n",
            "Turkish (Target): kimse yaralanmadı .\n",
            "Model   (Output): kimse yaralanmadı yaralanmadı .\n",
            "--------------------------------------------------\n",
            "Sample 28/50\n",
            "English (Source): both men were shot .\n",
            "Turkish (Target): her iki adam da vuruldu .\n",
            "Model   (Output): i kimiz de vuruldu vuruldu .\n",
            "--------------------------------------------------\n",
            "Sample 29/50\n",
            "English (Source): go get changed .\n",
            "Turkish (Target): git üstünü değiştir .\n",
            "Model   (Output): uyumak almaya git .\n",
            "--------------------------------------------------\n",
            "Sample 30/50\n",
            "English (Source): you re nice .\n",
            "Turkish (Target): sen hoşsun .\n",
            "Model   (Output): hoş hoş .\n",
            "--------------------------------------------------\n",
            "Sample 31/50\n",
            "English (Source): i must stay here .\n",
            "Turkish (Target): burada kalmalıyım .\n",
            "Model   (Output): burada kalmak zorundayım .\n",
            "--------------------------------------------------\n",
            "Sample 32/50\n",
            "English (Source): i ll tell tom .\n",
            "Turkish (Target): tom a söyleyeceğim .\n",
            "Model   (Output): tom a söylemeliyim söyleyeceğim .\n",
            "--------------------------------------------------\n",
            "Sample 33/50\n",
            "English (Source): tom is an alumnus .\n",
            "Turkish (Target): tom bir eski erkek öğrenci .\n",
            "Model   (Output): tom bir yetim .\n",
            "--------------------------------------------------\n",
            "Sample 34/50\n",
            "English (Source): let s not be naive .\n",
            "Turkish (Target): saf olmayalım .\n",
            "Model   (Output): saf olmayalım .\n",
            "--------------------------------------------------\n",
            "Sample 35/50\n",
            "English (Source): i ll let tom leave .\n",
            "Turkish (Target): tom un gitmesine izin vereceğim .\n",
            "Model   (Output): tom un gitmesine izin vereceğim .\n",
            "--------------------------------------------------\n",
            "Sample 36/50\n",
            "English (Source): tom has to be hot .\n",
            "Turkish (Target): tom ateşli olmalı .\n",
            "Model   (Output): tom sıcaktan bunalmış olmalı .\n",
            "--------------------------------------------------\n",
            "Sample 37/50\n",
            "English (Source): tom is an amateur .\n",
            "Turkish (Target): tom bir amatör .\n",
            "Model   (Output): tom kova yetim .\n",
            "--------------------------------------------------\n",
            "Sample 38/50\n",
            "English (Source): i m a cat person .\n",
            "Turkish (Target): kediciyimdir .\n",
            "Model   (Output): ben uzun bir kişiyim .\n",
            "--------------------------------------------------\n",
            "Sample 39/50\n",
            "English (Source): school s not fun .\n",
            "Turkish (Target): okul eğlenceli değildir .\n",
            "Model   (Output): eğlenceli eğlenceli değildir .\n",
            "--------------------------------------------------\n",
            "Sample 40/50\n",
            "English (Source): she is not here .\n",
            "Turkish (Target): o , burada değildir .\n",
            "Model   (Output): o , burada değildir .\n",
            "--------------------------------------------------\n",
            "Sample 41/50\n",
            "English (Source): i like your dress .\n",
            "Turkish (Target): elbisenizi beğendim .\n",
            "Model   (Output): elbiseni seviyorum .\n",
            "--------------------------------------------------\n",
            "Sample 42/50\n",
            "English (Source): tom never woke up .\n",
            "Turkish (Target): tom asla uyanmadı .\n",
            "Model   (Output): tom uyanmadı uyanmadı .\n",
            "--------------------------------------------------\n",
            "Sample 43/50\n",
            "English (Source): is that your book ?\n",
            "Turkish (Target): şu senin kitabın mı ?\n",
            "Model   (Output): o senin araban mı ?\n",
            "--------------------------------------------------\n",
            "Sample 44/50\n",
            "English (Source): can i go to work ?\n",
            "Turkish (Target): i şe gidebilir miyim ?\n",
            "Model   (Output): i şe gidebilir miyim ?\n",
            "--------------------------------------------------\n",
            "Sample 45/50\n",
            "English (Source): tom is thirsty .\n",
            "Turkish (Target): tom susadı .\n",
            "Model   (Output): tom susamış .\n",
            "--------------------------------------------------\n",
            "Sample 46/50\n",
            "English (Source): i forgave tom .\n",
            "Turkish (Target): tom u affettim .\n",
            "Model   (Output): tom u tekmeledim ettim .\n",
            "--------------------------------------------------\n",
            "Sample 47/50\n",
            "English (Source): he s not special .\n",
            "Turkish (Target): o özel değil .\n",
            "Model   (Output): o özel değil .\n",
            "--------------------------------------------------\n",
            "Sample 48/50\n",
            "English (Source): it couldn t be tom .\n",
            "Turkish (Target): o tom olamazdı .\n",
            "Model   (Output): o , olamazdı olamazdı .\n",
            "--------------------------------------------------\n",
            "Sample 49/50\n",
            "English (Source): it isn t that deep .\n",
            "Turkish (Target): o kadar derin değil .\n",
            "Model   (Output): o kadar derin değil .\n",
            "--------------------------------------------------\n",
            "Sample 50/50\n",
            "English (Source): how was your lunch ?\n",
            "Turkish (Target): öğle yemeğiniz nasıldı ?\n",
            "Model   (Output): öğle yemeğiniz nasıldı ?\n",
            "--------------------------------------------------\n",
            "\n",
            "Calculating metrics (BLEU & BERTScore)...\n",
            "\n",
            "FINAL RESULTS FOR LUONG ATTENTION:\n",
            "BLEU: 49.07 | BERTScore: 86.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 6: The Transformer"
      ],
      "metadata": {
        "id": "3MGr-UZPFFo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "\n",
        "# --- 1. SET DEVICE ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- 2. DIMENSIONS (Make sure input_lang and output_lang were defined before) ---\n",
        "try:\n",
        "    INPUT_DIM = len(input_lang.word2index)\n",
        "    OUTPUT_DIM = len(output_lang.word2index)\n",
        "except NameError:\n",
        "    print(\"HATA: input_lang veya output_lang bulunamadı! Lütfen veri ön işleme hücrelerini tekrar çalıştırın.\")\n",
        "\n",
        "# Hyperparameters\n",
        "D_MODEL = 512\n",
        "NHEAD = 8\n",
        "NUM_LAYERS = 4\n",
        "DIM_FEEDFORWARD = 1024\n",
        "LEARNING_RATE = 0.0003\n",
        "EPOCHS = 20\n",
        "DROPOUT = 0.1\n",
        "\n",
        "# --- 3. TRANSFORMER ARCHITECTURE ---\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x):\n",
        "        return self.dropout(x + self.pe[:x.size(0), :])\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, d_model, nhead, num_layers, dim_feedforward, dropout):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.src_embedding = nn.Embedding(input_dim, d_model)\n",
        "        self.trg_embedding = nn.Embedding(output_dim, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model, nhead=nhead, num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers, dim_feedforward=dim_feedforward, dropout=dropout\n",
        "        )\n",
        "        self.fc_out = nn.Linear(d_model, output_dim)\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        return mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        trg_mask = self.generate_square_subsequent_mask(trg.size(0)).to(trg.device)\n",
        "        src_emb = self.pos_encoder(self.src_embedding(src) * math.sqrt(self.d_model))\n",
        "        trg_emb = self.pos_encoder(self.trg_embedding(trg) * math.sqrt(self.d_model))\n",
        "        return self.fc_out(self.transformer(src_emb, trg_emb, tgt_mask=trg_mask))\n",
        "\n",
        "# --- 4. INITIALIZE & TRAIN ---\n",
        "model_transformer = TransformerModel(INPUT_DIM, OUTPUT_DIM, D_MODEL, NHEAD, NUM_LAYERS, DIM_FEEDFORWARD, DROPOUT).to(device)\n",
        "optimizer = optim.Adam(model_transformer.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0, label_smoothing=0.1)\n",
        "\n",
        "print(f\"Starting Training on {device}...\")\n",
        "for epoch in range(EPOCHS):\n",
        "    model_transformer.train()\n",
        "    epoch_loss = 0\n",
        "    for src, trg in train_loader:\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model_transformer(src, trg[:-1, :])\n",
        "        loss = criterion(output.view(-1, OUTPUT_DIM), trg[1:, :].view(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model_transformer.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "        print(f'Epoch: {epoch+1:02} | Loss: {epoch_loss/len(train_loader):.3f}')\n",
        "\n",
        "print(\"Training Complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc4vSor3Fbu7",
        "outputId": "a7713c0f-bfc5-42e3-8f3a-cfd93a545e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training on cuda...\n",
            "Epoch: 01 | Loss: 4.786\n",
            "Epoch: 05 | Loss: 3.919\n",
            "Epoch: 10 | Loss: 3.621\n",
            "Epoch: 15 | Loss: 3.459\n",
            "Epoch: 20 | Loss: 3.374\n",
            "Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "from bert_score import score as bert_score_func\n",
        "\n",
        "# --- TRANSFORMER TRANSLATION FUNCTION ---\n",
        "def translate_transformer(sentence, model, device, max_len=50):\n",
        "    model.eval()\n",
        "    tokens = [input_lang.word2index.get(token, 3) for token in preprocess(sentence).split()]\n",
        "    src_tensor = torch.tensor([1] + tokens + [2]).unsqueeze(1).to(device)\n",
        "\n",
        "    trg_indices = [1] # <sos>\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.tensor(trg_indices).unsqueeze(1).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(src_tensor, trg_tensor)\n",
        "\n",
        "        prediction = output.argmax(2)[-1, :].item()\n",
        "        trg_indices.append(prediction)\n",
        "        if prediction == 2: # <eos>\n",
        "            break\n",
        "\n",
        "    return \" \".join([output_lang.index2word[i] for i in trg_indices][1:-1])\n",
        "\n",
        "# --- DETAILED EVALUATION WITH SMOOTHING ---\n",
        "def evaluate_transformer_final_fixed(model, data, device, n_samples=50):\n",
        "    model.eval()\n",
        "    targets = []\n",
        "    outputs = []\n",
        "    chencherry = SmoothingFunction() # Fix for 0.00 BLEU\n",
        "\n",
        "    test_samples = data.sample(n_samples)\n",
        "\n",
        "    print(f\"\\n{'='*20} TRANSFORMER: DETAILED PERFORMANCE TEST {'='*20}\")\n",
        "\n",
        "    for i, (idx, row) in enumerate(test_samples.iterrows()):\n",
        "        src_sent = row['en']\n",
        "        trg_sent = row['tr']\n",
        "\n",
        "        # Generate translation\n",
        "        prediction = translate_transformer(src_sent, model, device)\n",
        "\n",
        "        targets.append([trg_sent.split()])\n",
        "        outputs.append(prediction.split())\n",
        "\n",
        "        # Exact format you requested\n",
        "        print(f\"Sample {i+1}/{n_samples}\")\n",
        "        print(f\"English (Source): {src_sent}\")\n",
        "        print(f\"Turkish (Target): {trg_sent}\")\n",
        "        print(f\"Model   (Output): {prediction}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    print(\"\\nCalculating metrics (BLEU & BERTScore)...\")\n",
        "\n",
        "    # BLEU with Smoothing Method 4 (Recommended for short sequences)\n",
        "    t_bleu = corpus_bleu(targets, outputs, smoothing_function=chencherry.method4) * 100\n",
        "\n",
        "    # BERTScore\n",
        "    ref_list = [\" \".join(r[0]) for r in targets]\n",
        "    hyp_list = [\" \".join(h) for h in outputs]\n",
        "    P, R, F1 = bert_score_func(hyp_list, ref_list, lang=\"tr\", verbose=False)\n",
        "    t_bs = F1.mean().item() * 100\n",
        "\n",
        "    print(f\"\\nFINAL RESULTS FOR TRANSFORMER:\")\n",
        "    print(f\"BLEU: {t_bleu:.2f} | BERTScore: {t_bs:.2f}\")\n",
        "\n",
        "    return t_bleu, t_bs\n",
        "\n",
        "# --- EXECUTE ---\n",
        "trans_bleu, trans_bs = evaluate_transformer_final_fixed(model_transformer, df, device)\n",
        "\n",
        "# Update the global results list\n",
        "if 'results_list' not in locals(): results_list = []\n",
        "# Remove old Transformer entry if exists to avoid duplicates\n",
        "results_list = [d for d in results_list if d.get('Model') != 'Transformer']\n",
        "results_list.append({\"Model\": \"Transformer\", \"BLEU\": trans_bleu, \"BERTScore\": trans_bs})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "289885cf099f43468d8ad49d39099467",
            "083e33e817ce4a5baf654f6519e195f1",
            "024634593f88419ebf330a3f1b9d9097",
            "88d9e517b64f45a78df6a40c723402c6",
            "553d8ea89bac467cbe2925485e5574c6",
            "786eca99f7f9405da7b7e057d09da17d",
            "a3e3d455a42e4e8fbc77aba8c9ff06dc",
            "22540efa571b4c0583ee2a07fb93f40a",
            "40b658642ba34044b5edda136ef30a29",
            "d136eb8ff9084188899b290979ce3b7c",
            "c8322c4451aa40798dbf99b1e5ffaf64",
            "b986ace9235d4ff5bc0e959239ef7b51",
            "6de9a64887b24dbaa46b21f8009a2f21",
            "0ccb4f3a17a0489e9fd85dfa630c3b43",
            "d5a8d2ec5f754c4f99453190152cf215",
            "169527d99b2a4c1faa688081db39d27c",
            "8a5a2f3cef534f2da1d49f7988ef367e",
            "b057515014b243bab5b9ff936e516e1a",
            "680574721419406ba37ca8e93b0894d8",
            "dfa56e904c8149799768dd87bfe3970e",
            "a071763cc4f04214a08f8945db74616a",
            "f125343f7c8740fa88e564d3e63a4b2d",
            "bff9e943b68e4bbbaac313eda096103e",
            "93cc780428b14acc80483d90e3b31d43",
            "f9634cb2496749b38c7718ee9ad64ef6",
            "3bd6c773bcd74cc5889378123cc390da",
            "ffd5c2dc403e471fad9b86b3db8046c7",
            "fa7329b7a338419fbf839e6339b41096",
            "d2663bbada684dae96d36755d92c91f7",
            "e57d6ad2608e4cf785d66e8186d62878",
            "510454ad3398452d856de4dd745a0dc0",
            "53377ac0ea744d65b1ab031e99c878a3",
            "6850037a81a04e2582074e05af8d0f4a",
            "d9ab65611c524d83ab4a53a7e283a1b3",
            "94f6c85814344d08a84479ab4f8118d3",
            "e9ba249903d143b3bd155cb58c76797f",
            "4d51e71904d442018494411e12c22e1a",
            "a7750b0da9af4d9f819fe8c840ba9965",
            "839ab1faa7ec49089c050997d2a29aa7",
            "a0ce681c0a8d413098f9496ff8ba4f46",
            "54cf10fc3f0a4337b70bb61dd4fcfb2f",
            "202facfea51140198ce95f04af94ea31",
            "0620cc1a511245b0a232fd62c1406bb7",
            "9bbc7546759f4fae9ee48151bea21d85"
          ]
        },
        "id": "2Z07VYUkILNb",
        "outputId": "7c780846-b4a4-4074-bd88-bea4224f4198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== TRANSFORMER: DETAILED PERFORMANCE TEST ====================\n",
            "Sample 1/50\n",
            "English (Source): tom jumped back .\n",
            "Turkish (Target): tom geriye atladı .\n",
            "Model   (Output): tom eve döndü .\n",
            "--------------------------------------------------\n",
            "Sample 2/50\n",
            "English (Source): tom waited calmly .\n",
            "Turkish (Target): tom sakince bekledi .\n",
            "Model   (Output): tom un üç oğlu .\n",
            "--------------------------------------------------\n",
            "Sample 3/50\n",
            "English (Source): tom kept eating .\n",
            "Turkish (Target): tom yemek yemeye devam etti .\n",
            "Model   (Output): tom un üç oğlu .\n",
            "--------------------------------------------------\n",
            "Sample 4/50\n",
            "English (Source): i m not a cop .\n",
            "Turkish (Target): ben bir polis değilim .\n",
            "Model   (Output): ben bir melek değilim .\n",
            "--------------------------------------------------\n",
            "Sample 5/50\n",
            "English (Source): put down that gun .\n",
            "Turkish (Target): o silahı yere koy .\n",
            "Model   (Output): onu tekrar çek .\n",
            "--------------------------------------------------\n",
            "Sample 6/50\n",
            "English (Source): let s wait a while .\n",
            "Turkish (Target): biraz bekleyelim .\n",
            "Model   (Output): bir göz atalım .\n",
            "--------------------------------------------------\n",
            "Sample 7/50\n",
            "English (Source): tom did that alone .\n",
            "Turkish (Target): tom onu tek başına yaptı .\n",
            "Model   (Output): tom onu yaptı .\n",
            "--------------------------------------------------\n",
            "Sample 8/50\n",
            "English (Source): i need that tape .\n",
            "Turkish (Target): o banda ihtiyacım var .\n",
            "Model   (Output): buna ihtiyacım olacak .\n",
            "--------------------------------------------------\n",
            "Sample 9/50\n",
            "English (Source): that s up to you .\n",
            "Turkish (Target): o size kalmış .\n",
            "Model   (Output): onu kontrol edelim .\n",
            "--------------------------------------------------\n",
            "Sample 10/50\n",
            "English (Source): you ll be ok now .\n",
            "Turkish (Target): artık iyi olacaksın .\n",
            "Model   (Output): şimdi olacaksın .\n",
            "--------------------------------------------------\n",
            "Sample 11/50\n",
            "English (Source): it s an old custom .\n",
            "Turkish (Target): bu eski bir gelenek .\n",
            "Model   (Output): o bir seçenek .\n",
            "--------------------------------------------------\n",
            "Sample 12/50\n",
            "English (Source): i m sleepy !\n",
            "Turkish (Target): uykum var !\n",
            "Model   (Output): bak !\n",
            "--------------------------------------------------\n",
            "Sample 13/50\n",
            "English (Source): that s the issue .\n",
            "Turkish (Target): konu odur .\n",
            "Model   (Output): o gerçekten iyi .\n",
            "--------------------------------------------------\n",
            "Sample 14/50\n",
            "English (Source): it was useless .\n",
            "Turkish (Target): o işe yaramazdı .\n",
            "Model   (Output): o gerçekten eğlenceliydi .\n",
            "--------------------------------------------------\n",
            "Sample 15/50\n",
            "English (Source): be seated .\n",
            "Turkish (Target): oturun .\n",
            "Model   (Output): dikkatli ol .\n",
            "--------------------------------------------------\n",
            "Sample 16/50\n",
            "English (Source): do tigers purr ?\n",
            "Turkish (Target): kaplanlar mırlar mı ?\n",
            "Model   (Output): birisi umurunda ?\n",
            "--------------------------------------------------\n",
            "Sample 17/50\n",
            "English (Source): i couldn t get it .\n",
            "Turkish (Target): ben anlayamadım .\n",
            "Model   (Output): onu sevmiyorum .\n",
            "--------------------------------------------------\n",
            "Sample 18/50\n",
            "English (Source): there was looting .\n",
            "Turkish (Target): yağma vardı .\n",
            "Model   (Output): oda boştu .\n",
            "--------------------------------------------------\n",
            "Sample 19/50\n",
            "English (Source): mary was a tomboy .\n",
            "Turkish (Target): mary erkek gibi kızdı .\n",
            "Model   (Output): mary bir ebe .\n",
            "--------------------------------------------------\n",
            "Sample 20/50\n",
            "English (Source): i m happy tonight .\n",
            "Turkish (Target): bu gece mutluyum .\n",
            "Model   (Output): ben iyiyim .\n",
            "--------------------------------------------------\n",
            "Sample 21/50\n",
            "English (Source): tom just shrugged .\n",
            "Turkish (Target): tom az önce omuz silkti .\n",
            "Model   (Output): tom az önce gitti .\n",
            "--------------------------------------------------\n",
            "Sample 22/50\n",
            "English (Source): we re not open .\n",
            "Turkish (Target): açık değiliz .\n",
            "Model   (Output): biz aptal değiliz .\n",
            "--------------------------------------------------\n",
            "Sample 23/50\n",
            "English (Source): you can have mine .\n",
            "Turkish (Target): benimkini alabilirsin .\n",
            "Model   (Output): yardım etmelisin .\n",
            "--------------------------------------------------\n",
            "Sample 24/50\n",
            "English (Source): aim higher .\n",
            "Turkish (Target): daha yükseği hedefle .\n",
            "Model   (Output): herkes ölür .\n",
            "--------------------------------------------------\n",
            "Sample 25/50\n",
            "English (Source): i m so overworked .\n",
            "Turkish (Target): çok çalıştım .\n",
            "Model   (Output): ben çok şanssızım .\n",
            "--------------------------------------------------\n",
            "Sample 26/50\n",
            "English (Source): i love my parents .\n",
            "Turkish (Target): ailemi severim .\n",
            "Model   (Output): ben bisikletimi .\n",
            "--------------------------------------------------\n",
            "Sample 27/50\n",
            "English (Source): tom agrees .\n",
            "Turkish (Target): tom kabul eder .\n",
            "Model   (Output): tom un üç oğlu .\n",
            "--------------------------------------------------\n",
            "Sample 28/50\n",
            "English (Source): tom isn t hurt .\n",
            "Turkish (Target): tom incinmiş değil .\n",
            "Model   (Output): tom aptal değil .\n",
            "--------------------------------------------------\n",
            "Sample 29/50\n",
            "English (Source): tom made a speech .\n",
            "Turkish (Target): tom bir konuşma yaptı .\n",
            "Model   (Output): tom un bir hizmetçisi var .\n",
            "--------------------------------------------------\n",
            "Sample 30/50\n",
            "English (Source): i don t often cry .\n",
            "Turkish (Target): ben sık sık ağlamam .\n",
            "Model   (Output): onu sevmiyorum .\n",
            "--------------------------------------------------\n",
            "Sample 31/50\n",
            "English (Source): don t kid around .\n",
            "Turkish (Target): dalga geçme .\n",
            "Model   (Output): o dinlemedi .\n",
            "--------------------------------------------------\n",
            "Sample 32/50\n",
            "English (Source): tom won t make it .\n",
            "Turkish (Target): tom bunu yapmayacak .\n",
            "Model   (Output): tom onu kullanamaz .\n",
            "--------------------------------------------------\n",
            "Sample 33/50\n",
            "English (Source): tom is such a jerk .\n",
            "Turkish (Target): tom aptalın teki .\n",
            "Model   (Output): tom bir bilim .\n",
            "--------------------------------------------------\n",
            "Sample 34/50\n",
            "English (Source): she is nice .\n",
            "Turkish (Target): o güzel .\n",
            "Model   (Output): o , diyet .\n",
            "--------------------------------------------------\n",
            "Sample 35/50\n",
            "English (Source): i had to smile .\n",
            "Turkish (Target): gülümsemek zorunda kaldım .\n",
            "Model   (Output): ben çalışmayı istiyorum .\n",
            "--------------------------------------------------\n",
            "Sample 36/50\n",
            "English (Source): do i annoy you ?\n",
            "Turkish (Target): seni sıkıyor muyum ?\n",
            "Model   (Output): sizinle konuşabilir miyim ?\n",
            "--------------------------------------------------\n",
            "Sample 37/50\n",
            "English (Source): we were miserable .\n",
            "Turkish (Target): sefil durumdaydık .\n",
            "Model   (Output): biz kazandık .\n",
            "--------------------------------------------------\n",
            "Sample 38/50\n",
            "English (Source): i will survive .\n",
            "Turkish (Target): hayatta kalacağım .\n",
            "Model   (Output): ben asla sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık\n",
            "--------------------------------------------------\n",
            "Sample 39/50\n",
            "English (Source): that doesn t help .\n",
            "Turkish (Target): o işe yaramaz .\n",
            "Model   (Output): onu yarı .\n",
            "--------------------------------------------------\n",
            "Sample 40/50\n",
            "English (Source): let s let tom win .\n",
            "Turkish (Target): tom un kazanmasına izin verelim .\n",
            "Model   (Output): tom u kovalım .\n",
            "--------------------------------------------------\n",
            "Sample 41/50\n",
            "English (Source): we never laughed .\n",
            "Turkish (Target): biz asla gülmedik .\n",
            "Model   (Output): biz kazandık .\n",
            "--------------------------------------------------\n",
            "Sample 42/50\n",
            "English (Source): three of them died .\n",
            "Turkish (Target): onların üçü öldü .\n",
            "Model   (Output): onlara yardımcı olabilir .\n",
            "--------------------------------------------------\n",
            "Sample 43/50\n",
            "English (Source): i hope tom says no .\n",
            "Turkish (Target): tom un hayır diyeceğini umuyorum .\n",
            "Model   (Output): tom un hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç hiç\n",
            "--------------------------------------------------\n",
            "Sample 44/50\n",
            "English (Source): we apologize .\n",
            "Turkish (Target): özür dileriz .\n",
            "Model   (Output): biz kazandık .\n",
            "--------------------------------------------------\n",
            "Sample 45/50\n",
            "English (Source): who spoke french ?\n",
            "Turkish (Target): kim fransızca konuştu ?\n",
            "Model   (Output): kim bilmek ?\n",
            "--------------------------------------------------\n",
            "Sample 46/50\n",
            "English (Source): it might just work .\n",
            "Turkish (Target): o sadece işe yarayabilir .\n",
            "Model   (Output): sadece onu yap .\n",
            "--------------------------------------------------\n",
            "Sample 47/50\n",
            "English (Source): tom is out there .\n",
            "Turkish (Target): tom orada .\n",
            "Model   (Output): tom un arabası .\n",
            "--------------------------------------------------\n",
            "Sample 48/50\n",
            "English (Source): i like tulips .\n",
            "Turkish (Target): laleleri seviyorum .\n",
            "Model   (Output): ben asla sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık sık\n",
            "--------------------------------------------------\n",
            "Sample 49/50\n",
            "English (Source): do you feel guilty ?\n",
            "Turkish (Target): suçlu hissediyor musun ?\n",
            "Model   (Output): sen gaz misin ?\n",
            "--------------------------------------------------\n",
            "Sample 50/50\n",
            "English (Source): where did you eat ?\n",
            "Turkish (Target): nerede yemek yedin ?\n",
            "Model   (Output): sen gaz misin ?\n",
            "--------------------------------------------------\n",
            "\n",
            "Calculating metrics (BLEU & BERTScore)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "289885cf099f43468d8ad49d39099467"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b986ace9235d4ff5bc0e959239ef7b51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bff9e943b68e4bbbaac313eda096103e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9ab65611c524d83ab4a53a7e283a1b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FINAL RESULTS FOR TRANSFORMER:\n",
            "BLEU: 1.87 | BERTScore: 60.69\n"
          ]
        }
      ]
    }
  ]
}